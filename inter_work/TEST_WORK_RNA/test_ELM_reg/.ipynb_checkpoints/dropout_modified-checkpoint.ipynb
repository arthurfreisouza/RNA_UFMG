{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1854e991-4dcc-477a-82fc-f8ef53c40a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import rpy2.robjects as ro\n",
    "from functools import partial\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.ipython import html\n",
    "html.html_rdataframe = partial(html.html_rdataframe, table_class = \"docutils\")\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df794220-b36f-4893-95fa-f38c7bc3f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(mlbench)\n",
    "datasetxor <- mlbench.xor(300)\n",
    "XR_datasetxor <- datasetxor$x\n",
    "LABELSR_datasetxor<- datasetxor$classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad0b0ed8-7c62-4553-a332-ef82b9a8fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects import numpy2ri\n",
    "numpy2ri.activate()\n",
    "x_df_xor = np.array(ro.r['XR_datasetxor'])\n",
    "labels_df_xor = np.array(ro.r['LABELSR_datasetxor'])\n",
    "labels_df_xor[labels_df_xor == 1] = -1\n",
    "labels_df_xor[labels_df_xor == 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6488db79-828b-457e-9cc2-4d8cc461d413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_df_xor, labels_df_xor, random_state = 0, train_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7bafa62b-1489-4dd3-85e9-5ca3afd1d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def train_ELM_DropOut(xin : np.ndarray, yin : np.ndarray, p : int, keep_rate : float, control : bool) -> list:\n",
    "    #np.set_printoptions(precision=10)\n",
    "    np.random.seed(np.random.randint(0, 10000))\n",
    "    \n",
    "    \n",
    "    n = xin.shape[1] # Pegando o número de valores de cada entrada.\n",
    "\n",
    "    # Z[n ou n + 1, p]\n",
    "    if control == True:\n",
    "        Z = np.zeros(((n + 1) * p)).reshape(n + 1, p)\n",
    "        for i in range(p):\n",
    "            random_seed = random.randint(0, 1000)\n",
    "            np.random.seed(random_seed)\n",
    "            random_weights = np.array([np.random.uniform(-0.5, 0.5) * 10 for _ in range((n + 1))]).reshape(n + 1,)\n",
    "            Z[ :, i] = random_weights\n",
    "        ones = np.ones((xin.shape[0], 1))\n",
    "        xin = np.concatenate((xin,ones), axis = 1)\n",
    "    else:\n",
    "        Z = np.zeros((n * p)).reshape(n, p)\n",
    "        for i in range(p):\n",
    "            random_seed = random.randint(0, 1000)\n",
    "            np.random.seed(random_seed)\n",
    "            random_weights = np.array([np.random.uniform(-0.5, 0.5) * 10 for _ in range(n)]).reshape(n,)\n",
    "            Z[ :, i] = random_weights\n",
    "        \n",
    "\n",
    "    Z_alter = Z\n",
    "\n",
    "    #print(f\"The matrix Z : {Z}\")\n",
    "    #print(f\"The mean of matrix Z : {np.mean(Z)}\")\n",
    "\n",
    "    try:\n",
    "        N_col_Z = Z_alter.shape[1]\n",
    "    except Exception as error:\n",
    "        if type(error) == IndexError:\n",
    "            print(f\" You don't have the necessary dimensions, so we will reshape your matrix w !\")\n",
    "            Z_alter = Z_alter.reshape(-1, 1)\n",
    "            N_col_Z = Z_alter.shape[1]\n",
    "    \n",
    "    for i in range(N_col_Z): # iterando sobre cada coluna.\n",
    "        N_dropped_neurons = int(np.ceil((1 - keep_rate) * Z_alter[:, i].shape[0])) # Pegando o número de neurônios que serão dropados.\n",
    "        lowest_val_idx = np.array(np.argsort(np.abs(Z_alter[:, i])[: N_dropped_neurons])) # Pegandos os índices dos neurônios que serão dropados.\n",
    "        for j in lowest_val_idx: # Zerando os pesos menos relevantes.\n",
    "            Z_alter[j, i] = 0\n",
    "\n",
    "\n",
    "\n",
    "    # A saída da rede é obtida com a pseudoinversa.\n",
    "    H = np.tanh(np.dot(xin, Z_alter))\n",
    "    #print(H)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    H = scaler.fit_transform(H)\n",
    "    ones = np.ones((H.shape[0], 1))\n",
    "    H = np.concatenate((H, ones), axis = 1)\n",
    "    #print(f\"The determinant of H : {np.linalg.det(H)}\")\n",
    "    #print(H)\n",
    "\n",
    "    w_1 = np.dot(np.transpose(H), H)\n",
    "    print(f\"The determinant of HtH : {np.linalg.det(w_1)}\")\n",
    "    #print(f\"The first part HTH is {w_1[ :2, :2]}\")\n",
    "    #print(f\" The mean of HTH is {np.mean(w_1)}\")\n",
    "\n",
    "\n",
    "    w_2 = np.linalg.inv(w_1)\n",
    "    #print(f\"The inverse of H-1 is {w_2[ :2, :2]}\")\n",
    "    #print(f\" The mean of the inverse is {np.mean(w_2)}\")\n",
    "    \n",
    "    w_3 = np.dot(w_2, np.transpose(H))\n",
    "    #print(f\"The third part H-1 is {w_3[ :5, :5]}\")\n",
    "    \n",
    "    w = np.dot(w_3, yin)\n",
    "    #print(f\"The last part is {w}\")\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        N_col_W = w.shape[1]\n",
    "    except Exception as error:\n",
    "        if type(error) == IndexError:\n",
    "            print(f\" You don't have the necessary dimensions, so we will reshape your matrix w !\")\n",
    "            w = w.reshape(-1, 1)\n",
    "            N_col_W = w.shape[1]\n",
    "        \n",
    "\n",
    "\n",
    "    for i in range(N_col_W): # Removendo os pesos menos relevantes da camada de saída.\n",
    "        N_dropped_neurons = int(np.ceil((1 - keep_rate) * w[:, i].shape[0])) # Pegando o número de neurônios que serão dropados.\n",
    "        lowest_val_idx = np.array(np.argsort(np.abs(w[:, i])[: N_dropped_neurons])) # Pegandos os índices dos neurônios que serão dropados.\n",
    "        for j in lowest_val_idx: # Zerando os pesos menos relevantes.\n",
    "            w[j, i] = 0\n",
    "\n",
    "    # Retornos.\n",
    "    return_list = list()\n",
    "    return_list.append(w)   \n",
    "    return_list.append(H)\n",
    "    return_list.append(Z) # Conexões são desligadas apenas no treino, portanto tenho que mandar a matriz Z completa.\n",
    "    return_list.append(Z_alter)\n",
    "    return  return_list\n",
    "\n",
    "\n",
    "def test_ELM(xin: np.ndarray, Z: np.ndarray, W: np.ndarray, control: bool):\n",
    "    \n",
    "    if control == True:\n",
    "        ones = np.ones((xin.shape[0], 1))\n",
    "        xin = np.concatenate((xin, ones), axis = 1)\n",
    "        \n",
    "    H = np.tanh(np.dot(xin, Z))\n",
    "    ones = np.ones((H.shape[0], 1))\n",
    "    H = np.concatenate((H, ones), axis = 1)\n",
    "    \n",
    "    Y_hat = np.sign(np.dot(H, W)) # Para problemas de classificação.\n",
    "    #Y_hat = np.dot(H, W) # Para problemas de regressão.\n",
    "    return Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f19500cb-c47a-4b56-afc8-d5c63d730724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The determinant of HtH : 1.866913609449826e-30\n",
      " You don't have the necessary dimensions, so we will reshape your matrix w !\n",
      "CPU times: user 5.42 ms, sys: 34.5 ms, total: 40 ms\n",
      "Wall time: 8.61 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p_neurons = 15\n",
    "ret = train_ELM_DropOut(xin = X_train, yin = y_train, p = p_neurons, keep_rate = 0.8, control = True)\n",
    "wxor = ret[0]\n",
    "hxor = ret[1]\n",
    "zxor = ret[2]\n",
    "z_alter = ret[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
